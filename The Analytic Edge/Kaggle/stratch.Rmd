---
title: "Analytic Edge Kaggle NYT classifiction"
author: "Ryan Zhang"
date: "Thursday, April 16, 2015"
output: html_document
---

# 0 Environment
# 环境设定
## Set working directory
## 设定工作环境
```{r}
setwd("~/GitHub/edX/The Analytic Edge/Kaggle")
```

## Load Libraries
## 函数包
```{r}
library(RTextTools)
library(plyr)
library(Matrix)
library(tm)
library(e1071)
library(caTools)
library(randomForest)
library(ROCR)
```

## Function Definition
## 自定义函数
```{r}
tCor <- function(t)round(t[,2]/rowSums(t),2)*100 
```

# 1 Data Preparing
# 1 数据准备工作
## 1.1 Data Loading
## 1.1 装载数据
```{r}
NewsTrain <- read.csv("NYTimesBlogTrain.csv", stringsAsFactors = F)
NewsTest <- read.csv("NYTimesBlogTest.csv", stringsAsFactors = F)
```

## 1.2 First Iteration in processing
## 1.2 第一轮数据处理
"Popular"" is the dependant variable, store it in a separate vector "Y", and delete the colomn from the 
dataframe "NewsTrain". 
要预测的因变量是“Popular”，将其存在一个单独的"Y"向量中,并从训练数据框中删除该列。
```{r}
Y <- as.factor(NewsTrain$Popular)
NewsTrain$Popular <- NULL
```

Store the number of training data points and the number of testing data points.
记录一下训练数据和测试数据的数量。
```{r}
ntrain <- nrow(NewsTrain)
ntest <- nrow(NewsTest)
ntrain
ntest
```

Combine "NewsTrain" and "NewsTest" into a single dataframe for the purpose of data preparing
将训练数据和测试数据合并为一个单一的数据框，以便集中处理（这是否有问题？）
```{r}
OriginalDF <- rbind(NewsTrain, NewsTest)
```

Filling empty entries for the first three columns with name "Other"
将前三列里面的“”用“Other”替代
```{r}
for (i in 1:nrow(OriginalDF)){
  for (j in 1:3){
    if (OriginalDF[i,j] == ""){
      OriginalDF[i,j] <- "Other"
    }
  }
}
```

Change the first three columns to be factors
将前三个变量改成factor类型
```{r}
OriginalDF$NewsDesk <- as.factor(OriginalDF$NewsDesk)
OriginalDF$SectionName <- as.factor(OriginalDF$SectionName)
OriginalDF$SubsectionName <- as.factor(OriginalDF$SubsectionName)
```

Transfer "WordCount" into Z-score
将WordCount转换为标准值
```{r}
OriginalDF$ZWordCount <- with(OriginalDF, (WordCount - mean(WordCount))/sd(WordCount))
OriginalDF$NWordCount <- log(OriginalDF$WordCount + 1)
```

Conver the PubDate and time variable to be more R friendly and extract the hour of day, the day on month and the day of week to be seperate variables. Finally delete the PubDate column.
将PubDate改成R的日期-时间格式，并将周几、每月几号以及每天几点这些信息单独抽取出来，删除原本的PubDate
```{r}
OriginalDF$PubDate <- strptime(OriginalDF$PubDate, "%Y-%m-%d %H:%M:%S")
OriginalDF$Hour <- as.factor(OriginalDF$PubDate$h)
OriginalDF$Wday <- as.factor(OriginalDF$PubDate$wday)
OriginalDF$Mday <- as.factor(OriginalDF$PubDate$mday)
OriginalDF$isWeekend <- as.numeric(OriginalDF$Wday %in% c(0,6))
OriginalDF$PubDate <- NULL
```

Generate training and testing set
生成训练和测试数据
```{r}
train <- OriginalDF[1:ntrain, c(1:3,7,9:14)]
test <- OriginalDF[(ntrain+1):nrow(OriginalDF),c(1:3,7,9:14)]
```

## 1.3 Exploratory Data Analysis
## 1.3 探索式数据分析
First Explore the few factor variable and their relationship to the depandent variable.
先看看前三个factor型数据与要预测的Popular之间的关系。
```{r}
tNewsDesk <- table(OriginalDF$NewsDesk[1:ntrain], Y)
tNewsDesk
tCor(tNewsDesk)
plot(tCor(tNewsDesk))

tSectionName <- table(OriginalDF$SectionName[1:ntrain], Y)
tSectionName
tCor(tSectionName)
plot(tCor(tSectionName))

tSubsectionName <- table(OriginalDF$SubsectionName[1:ntrain], Y)
tSubsectionName
tCor(tSubsectionName)
plot(tCor(tSubsectionName))
```

Looking at the text contents
看看文本信息
It seems that the "Snippet" is almost redudent with "Abstract", in since 98% cases they are the same. And "Abstract" contains a little bit more infomation than "Snippet"
Snippet应该和Abstract的重合内容非常多，前者貌T似都属于后者，因而估计只用后者就好了。
```{r}
sum(OriginalDF$Snippet == OriginalDF$Abstract)/nrow(OriginalDF)
which(OriginalDF$Snippet != OriginalDF$Abstract)[1]
OriginalDF[22,5]
OriginalDF[22,6]
```

Looking at WordCount
看看字数
The distribution of WordCount seems to be a longtail / power-law distribution.
字数的分布似乎是幂律分布的
```{r}
summary(OriginalDF$WordCount)
hist(OriginalDF$WordCount, breaks = 70)
hist(OriginalDF$NWordCount)
```


Looking at publication day/weekday/hour related to Popular
```{r}
tHour <- table(OriginalDF$Hour[1:ntrain] , Y)
tCor(tHour)
plot(tCor(tHour))

tWday <- table(OriginalDF$Wday[1:ntrain], Y)
tCor(tWday)
plot(tCor(tWday))

tMday <- table(OriginalDF$Mday[1:ntrain], Y)
tCor(tMday)
plot(tCor(tMday))

tWeekend <- table(OriginalDF$isWeekend[1:ntrain], Y)
tCor(tWeekend)
plot(tCor(tWeekend))
```

#2 Model fitting
#2 模型拟合

randomForest model
随机森林模型
```{r}
set.seed(123)
rfModel <- randomForest(x = train, y = Y, ntree = 500)
```

Make prediction on the training set
用模型对训练数据进行预测
```{r}
rfPred <- predict(rfModel, train, type = "prob")
table(rfPred[,2] > 0.5,Y)

prediction <- prediction(rfPred[,2], Y)
perf <- performance(prediction, "tpr", "fpr")
plot(perf, colorize = T, lwd = 2)
auc <- performance(prediction, "auc")
auc@y.values
```

Make prediction with randomForest model
用随机森林模型做预测
```{r}
tpred <- predict(rfModel, test, type = "prob")
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = tpred[,1])
write.csv(MySubmission, "rfOnRegularFeatures.csv", row.names = F)
```

#3 Try feature engineering with text content
#3 尝试通过文本数据做特征工程
Extract all headline and abstract to form a corpus
抽取题名和摘要文本构建一个语料库
```{r}
text <- vector()
for (i in 1:nrow(OriginalDF)) {
  text <- rbind(text, paste(OriginalDF$Headline[i], " ", OriginalDF$Abstract[i]))
}

Corpus <- Corpus(VectorSource(text))
```

Standard Corpus processing
标准化的语料库处理
```{r}
Corpus <- tm_map(Corpus, tolower)
Corpus <- tm_map(Corpus, PlainTextDocument)
Corpus <- tm_map(Corpus, removePunctuation)
Corpus <- tm_map(Corpus, removeWords, stopwords("english"))
Corpus <- tm_map(Corpus, stemDocument)
```

Document ~ TF-IDF matrix
构建文档~TFIDF矩阵
```{r}
dtm <- DocumentTermMatrix(Corpus, control = list(weighting = weightTfIdf))
```

Get the terms
获取术语列表
```{r}
terms <- dtm$dimnames$Terms
terms[5101:5110]
```

Get the matrix for training and testing set
分别获得训练和测试数据的Document~TF-IDF矩阵
```{r}
dtmTrain <- dtm[1:ntrain,]
dtmTest <- dtm[(1+ntrain):dtm$nrow,]
```

Get frequent terms matrix for testing set
获得测试集的频繁术语
```{r}
sparseTest <- removeSparseTerms(dtmTest, 0.95)
wordsTest <- as.data.frame(as.matrix(sparseTest))
termsTest <- names(wordsTest)
```

Filter the dtm based on frequent terms in testing set
根据测试集的频繁术语，对原本的矩阵进行筛选
```{r}
cols <- vector()
for (i in 1:length(termsTest)){
  cols = c(cols, which((terms == termsTest[i]) == T))
}
dtmFiltered <- dtm[,cols]
```

Text Feature
文本特征
```{r}
termFeatures <- as.data.frame(as.matrix(dtmFiltered))
row.names(termFeatures) <- c(1:nrow(OriginalDF))
```

Append text features to the dataframe
```{r}
TextADDDF <- as.data.frame(cbind(OriginalDF,termFeatures))
```

```{r}
tatrain <- TextADDDF[1:ntrain, c(1:3,7,9:25)]
tatest <- TextADDDF[(ntrain+1):nrow(TextADDDF),c(1:3,7,9:25)]
```

randomForest model with text features added
加了文本特征的随机森林模型
```{r}
set.seed(123)
tarfModel <- randomForest(x = tatrain, y = Y, ntree = 500)
```

Make prediction on the training set
用加了文本特征的随机森林模型对训练数据进行预测
```{r}
tarfPred <- predict(tarfModel, tatrain, type = "prob")
table(tarfPred[,2] > 0.5,Y)

prediction <- prediction(tarfPred[,2], Y)
perf <- performance(prediction, "tpr", "fpr")
plot(perf, colorize = T, lwd = 2)
auc <- performance(prediction, "auc")
auc@y.values
```

Make prediction with randomForest model
加了文本特征的随机森林模型做预测
```{r}
tatpred <- predict(tarfModel, tatest, type = "prob")
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = tpred[,1])
write.csv(MySubmission, "rfwith11textFeatures.csv", row.names = F)
```

#Why not a neural net?
#试试神经网络
```{r}
library(neuralnet)
traindata <- tatrain
traindata$Popular <- as.numeric(as.character(Y))

nn <- neuralnet(Popular~isWeekend+compani+day+new+presid+report+said+say+time+will+year+york,data = traindata, hidden=2, err.fct="ce", linear.output=FALSE)
plot(nn)
pnn <- compute(nn, traindata[,c(10:21)])
summary(tpnn$net.result)
nnpredict <- as.vector(pnn$net.result)
prediction <- prediction(nnpredict, Y)
perf <- performance(prediction, "tpr", "fpr")
plot(perf, colorize = T, lwd = 2)
auc <- performance(prediction, "auc")
auc@y.values
```


```{r}
taAll <- rbind(tatrain,tatest)
c1 <- as.data.frame(model.matrix(~taAll$NewsDesk))
c2 <- as.data.frame(model.matrix(~taAll$SectionName))
c3 <- as.data.frame(model.matrix(~taAll$SubsectionName))
c4 <- as.data.frame(model.matrix(~taAll$Hour))
c5 <- as.data.frame(model.matrix(~taAll$Wday))
c6 <- as.data.frame(model.matrix(~taAll$Mday))
d <- cbind(c1,c2,c3,c4,c5,c6,taAll[,c(4:6,10:21)])
d$"(Intercept)" <- NULL
d$"(Intercept)" <- NULL
d$"(Intercept)" <- NULL
d$"(Intercept)" <- NULL
d$"(Intercept)" <- NULL
d$"(Intercept)" <- NULL
names(d) <- make.names(names(d))
traind <- d[1:ntrain,]
traind$Popular <- as.numeric(as.character(Y))
testd <- d[(ntrain+1:nrow(d)),]
n <- names(d)
f <- as.formula(paste("Popular ~", paste(n[!n %in% "Popular"], collapse = " + ")))
f
nn <- neuralnet(f,data = traind, hidden=10, err.fct="ce", linear.output=FALSE)
```

